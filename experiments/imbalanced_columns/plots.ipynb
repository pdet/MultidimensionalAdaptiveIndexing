{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import json\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read config\n",
    "with open('config.json') as json_file:\n",
    "    f = json.load(json_file)\n",
    "    NUMBER_OF_QUERIES = f['number_of_queries']\n",
    "    REPETITIONS = f['repetitions']\n",
    "    ROWS = f['rows']\n",
    "    SELECTIVITIES = [0.0]\n",
    "    COLS = ['10']\n",
    "    EXPS_DEFAULTS = f['experiments']\n",
    "    PARTITION_SIZE = f['partition_size']\n",
    "    PROGRESSIVE_INDEX_DELTAS = f['deltas']\n",
    "\n",
    "# Algorithms and Experiments defitions\n",
    "algorithms = {\n",
    "    'AverageKDTree': {\n",
    "        'name': 'average_kd_tree',\n",
    "        'color': 'red',\n",
    "        'dash': 'dot',\n",
    "        'show_name': 'AvgKD',\n",
    "        'type': 'full_index',\n",
    "        'delta': '0.0',\n",
    "        'partition_size': PARTITION_SIZE\n",
    "    },\n",
    "    'MedianKDTree': {\n",
    "        'name': 'median_kd_tree',\n",
    "        'color': 'red',\n",
    "        'dash': 'solid',\n",
    "        'show_name': 'MedKD',\n",
    "        'type': 'full_index',\n",
    "        'delta': '0.0',\n",
    "        'partition_size': PARTITION_SIZE\n",
    "    },\n",
    "#     'CrackingKDTree': {\n",
    "#         'name': 'cracking_kd_tree',\n",
    "#         'color': 'green',\n",
    "#         'dash': 'dot',\n",
    "#         'show_name': 'AKD',\n",
    "#         'type': 'adaptive',\n",
    "#         'delta': '0.0',\n",
    "#         'partition_size': PARTITION_SIZE\n",
    "#     },\n",
    "#     'Quasii': {\n",
    "#         'name': 'quasii',\n",
    "#         'color': 'green',\n",
    "#         'dash': 'solid',\n",
    "#         'show_name': 'Q',\n",
    "#         'type': 'adaptive',\n",
    "#         'delta': '0.0',\n",
    "#         'partition_size': PARTITION_SIZE\n",
    "#     },\n",
    "    'FullScan': {\n",
    "        'name': 'full_scan_cl',\n",
    "        'color': 'black',\n",
    "        'dash': 'dot',\n",
    "        'show_name': 'FS',\n",
    "        'type': 'full_index',\n",
    "        'partition_size': '0',\n",
    "        'delta':'0.0',\n",
    "    },\n",
    "    'ProgressiveIndexCostModel': {\n",
    "        'name': 'progressive_index_cm',\n",
    "        'color': 'purple',\n",
    "        'dash': 'dot',\n",
    "        'show_name': 'GPKD(.2)',\n",
    "        'type': 'adaptive',\n",
    "        'delta': PROGRESSIVE_INDEX_DELTAS[0],\n",
    "        'partition_size': PARTITION_SIZE\n",
    "    },\n",
    "    'ProgressiveIndex': {\n",
    "        'name': 'progressive_index',\n",
    "        'color': 'purple',\n",
    "        'dash': 'solid',\n",
    "        'show_name': 'PKD(.2)',\n",
    "        'type': 'adaptive',\n",
    "        'delta': PROGRESSIVE_INDEX_DELTAS[0],\n",
    "        'partition_size': PARTITION_SIZE\n",
    "    }\n",
    "}\n",
    "\n",
    "for key, value in algorithms.items():\n",
    "    name = value['name']\n",
    "    delta = value['delta']\n",
    "    partition_size = value['partition_size']\n",
    "    algorithms[key]['alg_id'] = f\"{name}-{delta}-{partition_size}\"\n",
    "    \n",
    "# Synthetic Experiments\n",
    "experiments = {}\n",
    "\n",
    "for i in [10]:\n",
    "    temp = {\n",
    "        f'ImbalancedDescending{i}': {\n",
    "            \"name\": f\"ImbalancedDescending({i})\",\n",
    "            'name-in-file': 'imbalanced_columns_descending',\n",
    "            'n_rows': ROWS,\n",
    "            'n_queries': NUMBER_OF_QUERIES,\n",
    "            'n_cols': f'{i}',\n",
    "            'sel': '0.0',\n",
    "        },\n",
    "        f'ImbalancedAscending{i}': {\n",
    "            \"name\": f\"ImbalancedAscending({i})\",\n",
    "            'name-in-file': 'imbalanced_columns_ascending',\n",
    "            'n_rows': ROWS,\n",
    "            'n_queries': NUMBER_OF_QUERIES,\n",
    "            'n_cols': f'{i}',\n",
    "            'sel': '0.0',\n",
    "        },\n",
    "    }\n",
    "    experiments = {**experiments, **temp}\n",
    "    \n",
    "for key, value in experiments.items():\n",
    "    name = value['name-in-file']\n",
    "    rows = value['n_rows']\n",
    "    n_queries = value['n_queries']\n",
    "    cols = value['n_cols']\n",
    "    sel = value['sel']\n",
    "    experiments[key]['exp_id'] = f\"{name}-{rows}-{n_queries}-{cols}-{sel}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input/Output\n",
    "def read(alg, exp):\n",
    "    if exp.startswith('Shifting'):\n",
    "        n_queries_per_run = 10\n",
    "        uni = read(alg, 'Uniform' + experiments[exp]['n_cols'])\n",
    "        n_runs = int(len(uni)/n_queries_per_run) - 1\n",
    "        df_final = uni.head(n_queries_per_run)\n",
    "        for _ in range(int(n_runs)):\n",
    "            temp = uni.head(n_queries_per_run).copy()\n",
    "            df_final = df_final.append(temp, ignore_index=True)\n",
    "    else:\n",
    "        df = pd.read_csv(f\"results/{algorithms[alg]['alg_id']}-{experiments[exp]['exp_id']}.csv\")\n",
    "        repetitions = df['repetition'].max() + 1\n",
    "        step = int(len(df.index)/repetitions)\n",
    "        df_final = df[:step].copy().reset_index()\n",
    "        for rep in range(1, repetitions):\n",
    "            df_final += df[step * (rep) : step * (rep + 1)].copy().reset_index()\n",
    "\n",
    "        df_final = df_final/repetitions\n",
    "    \n",
    "    if 'index_search_time' not in df_final:\n",
    "        df_final['index_search_time'] = 0.0\n",
    "    if 'tuples_scanned' not in df_final:\n",
    "        df_final['tuples_scanned'] = 0.0\n",
    "    if 'number_of_nodes' not in df_final:\n",
    "        df_final['number_of_nodes'] = 0.0\n",
    "    df_final['query_time'] = df_final['initialization_time'] + df_final['index_search_time'] + df_final['scan_time'] + df_final['adaptation_time']\n",
    "    df_final['query_time_cumsum'] = df_final['query_time'].cumsum()\n",
    "    return df_final\n",
    "\n",
    "                     \n",
    "def read_multiple(algs, exp):\n",
    "    ''' Reads multiple algorithms in an experiment, return three arrays: dfs, colors, names\n",
    "    '''\n",
    "    dfs = []\n",
    "    colors = []\n",
    "    names = []\n",
    "    dashes = []\n",
    "    for alg in algs:\n",
    "        dfs.append(read(alg, exp))\n",
    "        names.append(algorithms[alg]['show_name'])\n",
    "        colors.append(algorithms[alg]['color'])\n",
    "        dashes.append(algorithms[alg]['dash'])\n",
    "    \n",
    "    return dfs, colors, dashes, names,\n",
    "\n",
    "                     \n",
    "def save_figure(fig, fig_name):\n",
    "    fig.write_image(f\"figures/{fig_name}\", width=1024, height=768)\n",
    "                     \n",
    "def save_table(table, table_name):\n",
    "    with open(f\"tables/{table_name}\", 'w') as f:\n",
    "        f.write(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper methods\n",
    "def get_first_query(df):\n",
    "    return df['query_time'].iloc[0]\n",
    "\n",
    "def get_payoff(df, baseline):\n",
    "    p = [i for i, x in enumerate(df['query_time_cumsum'] - (baseline['query_time_cumsum'])) if x > 0]\n",
    "    if len(p) == 0:\n",
    "        return len(df)\n",
    "    return p[-1]\n",
    "\n",
    "def get_convergence(df, df_type=''):\n",
    "    if df_type == 'full_index':\n",
    "        return 0\n",
    "    c = [i for i, x in enumerate(df['adaptation_time']) if x != 0.0]\n",
    "    if(len(c) == 0):\n",
    "        return len(c)\n",
    "    else:\n",
    "        return c[-1]\n",
    "\n",
    "def get_robustness(df, df_type=''):\n",
    "    if df_type == 'full_index':\n",
    "        return 0\n",
    "    return np.var(df['query_time'][:min(50, get_convergence(df, df_type))])\n",
    "\n",
    "def get_total_time(df, lower=0, upper=-1):\n",
    "    return df['query_time'][lower:upper].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figures\n",
    "\n",
    "delta_cols = [2, 4, 5, 6, 7, 8]\n",
    "delta_markers = ['circle', 'square', 'x', 'star', 'triangle-up', 'diamond']\n",
    "\n",
    "def create_figure(data=[]):\n",
    "    fig = go.Figure(\n",
    "        data=data,\n",
    "        layout=go.Layout(\n",
    "#             width=1500,\n",
    "            plot_bgcolor='rgba(0,0,0,0)',\n",
    "            font=dict(\n",
    "                size=42\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                showline=True,\n",
    "                linewidth=2,\n",
    "                linecolor='black',\n",
    "                showgrid=True,\n",
    "                gridwidth=1,\n",
    "                gridcolor='lightgrey',\n",
    "                zeroline=False,\n",
    "                zerolinecolor='rgba(0, 0, 0, 0)',\n",
    "                ticks=\"inside\",\n",
    "                ticklen=5\n",
    "            ),\n",
    "            xaxis=dict(\n",
    "                showline=True,\n",
    "                linewidth=2,\n",
    "                linecolor='black',\n",
    "                ticks='inside',\n",
    "                zeroline=True,\n",
    "                ticklen=5\n",
    "            ),\n",
    "            legend=dict(\n",
    "                font=dict(\n",
    "                    size=30,\n",
    "                    color=\"black\"\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "def line(exp, algs, attr, limit=2000):\n",
    "    dfs, colors, dashes, names = read_multiple(algs, exp)\n",
    "    fig = create_figure()\n",
    "    \n",
    "    lines = []\n",
    "    \n",
    "    biggest = 0\n",
    "    \n",
    "    for i, df in enumerate(dfs):\n",
    "        per_query_times = np.array(df[attr][:limit])\n",
    "        if biggest < np.max(per_query_times):\n",
    "            biggest = np.max(per_query_times)\n",
    "        lines.append(\n",
    "            go.Scatter(\n",
    "                name=names[i],\n",
    "                x=list(range(len(per_query_times))),\n",
    "                y=per_query_times,\n",
    "#                 marker_color=colors[i],\n",
    "                mode='lines',\n",
    "                line=dict(width=4, dash=dashes[i])\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    fig.add_traces(data=lines)\n",
    "    fig.update_layout(showlegend=True, yaxis_title=attr)\n",
    "    return fig\n",
    "\n",
    "def workload_selectivity(exp):\n",
    "    fig = create_figure()\n",
    "    df = read('FullScan', exp)\n",
    "    sel = ((df['tuples_scanned']/df['scan_overhead'])/df['tuples_scanned']) * 100\n",
    "    \n",
    "    fig.add_traces(\n",
    "        data=go.Scatter(\n",
    "            name='selectivity',\n",
    "            x=list(range(len(sel))),\n",
    "            y=sel,\n",
    "            mode='lines',\n",
    "            line=dict(width=4)\n",
    "        )\n",
    "    )\n",
    "    fig.update_layout(showlegend=True, yaxis_title='Selectivity (%)')\n",
    "    return fig\n",
    "\n",
    "\n",
    "def per_query(exp, algs, limit=1000):\n",
    "    dfs, colors, dashes, names = read_multiple(algs, exp)\n",
    "    fig = create_figure()\n",
    "    \n",
    "    lines = []\n",
    "    \n",
    "    biggest = 0\n",
    "    \n",
    "    for i, df in enumerate(dfs):\n",
    "        alg = algs[i]\n",
    "        per_query_times = np.array(df['query_time'][:limit]) * 1000\n",
    "        if biggest < np.max(per_query_times):\n",
    "            biggest = np.max(per_query_times)\n",
    "        lines.append(\n",
    "            go.Scatter(\n",
    "                name=names[i],\n",
    "                x=list(range(len(per_query_times))),\n",
    "                y=per_query_times,\n",
    "                marker_color=colors[i],\n",
    "                mode='lines',\n",
    "                line=dict(width=6, dash=dashes[i])\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    fig.add_traces(data=lines)\n",
    "    fig.update_layout(showlegend=True, yaxis_title='Time (milliseconds)')\n",
    "    fig.update_layout(legend_orientation=\"h\", legend=dict(x=.25, y=1.2))\n",
    "    fig.update_yaxes(type=\"log\")\n",
    "    return fig\n",
    "\n",
    "def cummulative(exp, algs, limit=5000):\n",
    "    dfs, colors, dashes, names = read_multiple(algs, exp)\n",
    "    fig = create_figure()\n",
    "    \n",
    "    lines = []\n",
    "    \n",
    "    biggest = 0\n",
    "    \n",
    "    for i, df in enumerate(dfs):\n",
    "        alg = algs[i]\n",
    "        per_query_times = np.array(df['query_time_cumsum'][:limit])\n",
    "        lines.append(\n",
    "            go.Scatter(\n",
    "                name=names[i],\n",
    "                x=list(range(len(per_query_times))),\n",
    "                y=per_query_times,\n",
    "                marker_color=colors[i],\n",
    "                mode='lines',\n",
    "                line=dict(width=6, dash=dashes[i])\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    fig.add_traces(data=lines)\n",
    "    fig.update_layout(legend_orientation=\"h\", legend=dict(x=.25, y=1.2))\n",
    "    fig.update_layout(showlegend=True, yaxis_title='Time (Seconds)')\n",
    "    return fig\n",
    "\n",
    "def number_of_nodes(exp, algs, limit=5000):\n",
    "    dfs, colors, dashes, names = read_multiple(algs, exp)\n",
    "    fig = create_figure()\n",
    "    \n",
    "    lines = []\n",
    "    \n",
    "    biggest = 0\n",
    "    \n",
    "    for i, df in enumerate(dfs):\n",
    "        per_query_times = np.array(df['number_of_nodes'][:limit])\n",
    "        if biggest < np.max(per_query_times):\n",
    "            biggest = np.max(per_query_times)\n",
    "        lines.append(\n",
    "            go.Scatter(\n",
    "                name=names[i],\n",
    "                x=list(range(len(per_query_times))),\n",
    "                y=per_query_times,\n",
    "                marker_color=colors[i],\n",
    "                mode='lines',\n",
    "                line=dict(width=6, dash=dashes[i])\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    fig.add_traces(data=lines)\n",
    "    fig.update_layout(legend_orientation=\"h\", legend=dict(x=.25, y=1.2))\n",
    "    fig.update_layout(showlegend=True, yaxis_title='# Nodes')\n",
    "    return fig\n",
    "\n",
    "def tuples_scanned(exp, algs, limit=5000):\n",
    "    dfs, colors, dashes, names = read_multiple(algs, exp)\n",
    "    fig = create_figure()\n",
    "    \n",
    "    lines = []\n",
    "    \n",
    "    \n",
    "    for i, df in enumerate(dfs):\n",
    "        per_query_times = np.array(df['tuples_scanned'][:limit])\n",
    "        lines.append(\n",
    "            go.Scatter(\n",
    "                name=names[i],\n",
    "                x=list(range(len(per_query_times))),\n",
    "                y=per_query_times,\n",
    "                marker_color=colors[i],\n",
    "                mode='lines',\n",
    "                line=dict(width=6, dash=dashes[i])\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    fig.add_traces(data=lines)\n",
    "    fig.update_layout(legend_orientation=\"h\", legend=dict(x=.25, y=1.2))\n",
    "    fig.update_layout(showlegend=True, yaxis_title='Tuples Scanned')\n",
    "    return fig\n",
    "\n",
    "def break_down(exp, algs, limit):\n",
    "    dfs, _, _, names = read_multiple(algs, exp)\n",
    "    initializations = np.array([x['initialization_time'][:limit].sum() for x in dfs])\n",
    "    adaptation = np.array([x['adaptation_time'][:limit].sum() for x in dfs])\n",
    "    search = np.array([x['index_search_time'][:limit].sum() for x in dfs])\n",
    "    scan = np.array([x['scan_time'][:limit].sum() for x in dfs])\n",
    "    \n",
    "#     fig = create_figure(data=[\n",
    "#         go.Bar(name='Initialization', x=names, y=initializations, marker_color='rgb(176, 201, 146)'),\n",
    "#         go.Bar(name='Adaptation', x=names, y=adaptation, marker_color='rgb(195, 114, 28)'),\n",
    "#         go.Bar(name='Index Search', x=names, y=search, marker_color='rgb(197, 255, 114)'),\n",
    "#         go.Bar(name='Scan', x=names, y=scan, marker_color='rgb(237, 218, 123)'),\n",
    "#     ])\n",
    "\n",
    "    scan_color = '#AB63FA'\n",
    "    index_search_color = '#03CC96'\n",
    "    adaptation_color = '#EF553B'\n",
    "    initialization_color = '#636EFA'\n",
    "\n",
    "    data = [\n",
    "        go.Bar(name='Initialization', x=names, y=initializations, width=0.5, marker_color=initialization_color, showlegend=False),\n",
    "        go.Bar(name='Adaptation', x=names, y=adaptation, width=0.5, marker_color=adaptation_color, showlegend=False),\n",
    "        go.Bar(name='Index Search', x=names, y=search, width=0.5, marker_color=index_search_color,showlegend=False),\n",
    "        go.Bar(name='Scan', x=names, y=scan, width=0.5, marker_color=scan_color,showlegend=False),\n",
    "    ]\n",
    "    \n",
    "    data.append(\n",
    "        go.Scatter(\n",
    "            name='Initialization',\n",
    "            x=[None],\n",
    "            y=[None],\n",
    "            mode='markers',\n",
    "            marker_color=initialization_color,\n",
    "            marker=dict(\n",
    "                size=40,\n",
    "                symbol='square'\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    data.append(\n",
    "        go.Scatter(\n",
    "            name='Adaptation',\n",
    "            x=[None],\n",
    "            y=[None],\n",
    "            mode='markers',\n",
    "            marker_color=adaptation_color,\n",
    "            marker=dict(\n",
    "                size=40,\n",
    "                symbol='square'\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    data.append(\n",
    "        go.Scatter(\n",
    "            name='Index Search',\n",
    "            x=[None],\n",
    "            y=[None],\n",
    "            mode='markers',\n",
    "            marker_color=index_search_color,\n",
    "            marker=dict(\n",
    "                size=40,\n",
    "                symbol='square'\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    data.append(\n",
    "        go.Scatter(\n",
    "            name='Scan',\n",
    "            x=[None],\n",
    "            y=[None],\n",
    "            mode='markers',\n",
    "            marker_color=scan_color,\n",
    "            marker=dict(\n",
    "                size=40,\n",
    "                symbol='square'\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig = create_figure(data=data)\n",
    "    \n",
    "    # Change the bar mode\n",
    "    fig.update_layout(barmode='stack')\n",
    "    fig.update_layout(legend_orientation=\"h\", legend=dict(x=.25, y=1.2))\n",
    "    fig.update_layout(yaxis_title='Time (seconds)')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latex Tables\n",
    "\n",
    "def pandas_to_latex(df, highlight='min', ignore_last=False, float_format=\"%.2f\"):\n",
    "    mins = []\n",
    "    maxs = []\n",
    "    for i in range(len(df)):\n",
    "        row = df.iloc[i]\n",
    "        c_min = float('inf')\n",
    "        c_max = -float('inf')\n",
    "        if ignore_last:\n",
    "            length = len(row) - 1\n",
    "        else:\n",
    "            length = len(row)\n",
    "        for j in range(length):\n",
    "            if row[j] == '-' or row[j] == '*':\n",
    "                continue\n",
    "            if c_min > float(row[j]):\n",
    "                c_min = float(row[j])\n",
    "            if c_max < float(row[j]):\n",
    "                c_max = float(row[j])\n",
    "        mins.append(c_min)\n",
    "        maxs.append(c_max)\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        row = df.iloc[i]\n",
    "        for j in range(len(row)):\n",
    "            if row[j] == '-' or row[j] == '*':\n",
    "                continue\n",
    "            if highlight == 'min':\n",
    "                if float(row[j]) == mins[i]:\n",
    "                    row[j] = \"\\cellcolor{green!25}\" + (float_format % float(row[j]))\n",
    "                else:\n",
    "                    row[j] = float_format % float(row[j])\n",
    "            if highlight == 'max':\n",
    "                if float(row[j]) == maxs[i]:\n",
    "                    row[j] = \"\\cellcolor{green!25}\" + (float_format % float(row[j]))\n",
    "                else:\n",
    "                    row[j] = float_format % float(row[j])\n",
    "    \n",
    "    return df.to_latex(multicolumn=True, multirow=True, escape=False)\n",
    "\n",
    "def metrics(exps, algs):\n",
    "    '''\n",
    "    ||||||||||||Algorithm 1| Algorithm 2|...\n",
    "    First Query|   1.11.   |     15.    |...\n",
    "    ...\n",
    "    '''\n",
    "    data = {}\n",
    "\n",
    "    # create indexes\n",
    "    index_exp = []\n",
    "    index_metric = []\n",
    "    \n",
    "    \n",
    "    metrics = ['First Query', 'PayOff', 'Convergence', 'Robustness', 'Time']\n",
    "\n",
    "    \n",
    "    for exp in exps:\n",
    "        dfs, _, _, names = read_multiple(algs, exp)\n",
    "        \n",
    "        # initialize the data dict with empty arrays for each algorithm\n",
    "        for name in names:\n",
    "            if name not in data:\n",
    "                data[name] = []\n",
    "\n",
    "        baseline = read('FullScan', exp)\n",
    "\n",
    "        index_exp += [experiments[exp]['name']] * len(metrics)\n",
    "        index_metric += metrics\n",
    "        \n",
    "        for df, name, alg in zip(dfs, names, algs):\n",
    "            data[name].append('%.2f' % get_first_query(df))\n",
    "            po = get_payoff(df, baseline)\n",
    "            if po == len(df):\n",
    "                data[name].append('-')\n",
    "            else:\n",
    "                data[name].append(po)\n",
    "            conv = get_convergence(df, algorithms[alg]['type'])\n",
    "            if conv == 0:\n",
    "                data[name].append('-')\n",
    "            elif conv >= len(df)-1:\n",
    "                data[name].append('*')\n",
    "            else:\n",
    "                data[name].append(conv)\n",
    "            \n",
    "            robust = get_robustness(df, algorithms[alg]['type'])\n",
    "            if robust == 0:\n",
    "                data[name].append('-') \n",
    "            else:\n",
    "                data[name].append('%.E' % robust)\n",
    "            \n",
    "            \n",
    "            data[name].append('%.2f' %get_total_time(df))\n",
    "\n",
    "    index = [index_exp, index_metric]\n",
    "    df = pd.DataFrame(data, index=index)\n",
    "\n",
    "    return df\n",
    "    \n",
    "    latex = df.to_latex(multicolumn=True, multirow=True)\n",
    "\n",
    "    for exp in exps:\n",
    "        latex = latex.replace(exp, \"\\\\rotatebox[origin=c]{90}{%s}\" % exp)\n",
    "    return latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MedKD</th>\n",
       "      <th>AvgKD</th>\n",
       "      <th>PKD(.2)</th>\n",
       "      <th>GPKD(.2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">ImbalancedDescending(10)</td>\n",
       "      <td>First Query</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PayOff</td>\n",
       "      <td>41</td>\n",
       "      <td>27</td>\n",
       "      <td>72</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Convergence</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>44</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Robustness</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1E-03</td>\n",
       "      <td>2E-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Time</td>\n",
       "      <td>16.08</td>\n",
       "      <td>17.44</td>\n",
       "      <td>16.54</td>\n",
       "      <td>17.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">ImbalancedAscending(10)</td>\n",
       "      <td>First Query</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PayOff</td>\n",
       "      <td>108</td>\n",
       "      <td>85</td>\n",
       "      <td>73</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Convergence</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>44</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Robustness</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2E-04</td>\n",
       "      <td>2E-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Time</td>\n",
       "      <td>6.39</td>\n",
       "      <td>6.28</td>\n",
       "      <td>5.30</td>\n",
       "      <td>4.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      MedKD  AvgKD PKD(.2) GPKD(.2)\n",
       "ImbalancedDescending(10) First Query   1.65   1.12    0.10     0.10\n",
       "                         PayOff          41     27      72       94\n",
       "                         Convergence      -      -      44       45\n",
       "                         Robustness       -      -   1E-03    2E-04\n",
       "                         Time         16.08  17.44   16.54    17.96\n",
       "ImbalancedAscending(10)  First Query   1.95   1.47    0.07     0.07\n",
       "                         PayOff         108     85      73       59\n",
       "                         Convergence      -      -      44       17\n",
       "                         Robustness       -      -   2E-04    2E-04\n",
       "                         Time          6.39   6.28    5.30     4.74"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exps = ['Uniform8', 'Skewed8', 'ZoomIn8', 'Periodic8', 'SequentialZoomIn8', 'AlternatingZoomIn8', 'Shifting8', 'Sequential2',]\n",
    "exps = ['ImbalancedDescending10', 'ImbalancedAscending10']\n",
    "m = metrics(exps, [\n",
    "        'MedianKDTree',\n",
    "        'AverageKDTree',\n",
    "        'ProgressiveIndex',\n",
    "        'ProgressiveIndexCostModel',\n",
    "])\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descending\n",
    "Columns selectivity: 1, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1\n",
    "This is the worst case because the nodes near the root do not help much with the query, specially the root, which has selecitivity equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = per_query('ImbalancedDescending10', [\n",
    "        'MedianKDTree',\n",
    "\n",
    "        'ProgressiveIndex',\n",
    "        'ProgressiveIndexCostModel',\n",
    "], 90)\n",
    "fig.update_layout(\n",
    "    title=\"Descending (1 to 0.1)\"\n",
    ")\n",
    "fig.write_image('worst-case.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ascending\n",
    "Columns selectivity: 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.9, 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = per_query('ImbalancedAscending10', [\n",
    "        'MedianKDTree',\n",
    "        'ProgressiveIndex',\n",
    "        'ProgressiveIndexCostModel',\n",
    "], 90)\n",
    "fig.update_layout(\n",
    "    title=\"Ascending (0.1 to 1)\"\n",
    ")\n",
    "fig.write_image('best-case.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
